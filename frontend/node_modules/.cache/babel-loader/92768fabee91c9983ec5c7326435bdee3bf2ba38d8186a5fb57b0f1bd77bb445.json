{"ast":null,"code":"var _jsxFileName = \"/Users/komasz/Documents/GitHub/ai-voice/frontend/src/components/AudioChat/AudioChat.tsx\",\n  _s = $RefreshSig$();\nimport React, { useCallback, useEffect, useMemo, useState, useRef } from 'react';\nimport { socket } from '../../services/socket';\nimport { makeAutoObservable } from 'mobx';\nimport { AudioChatIconButton, AudioChatRuningIcon, StopAudioIconButton, ChatRuningWrapper } from './AudioChat.styled';\nimport { playStartListeningSound, playStopListeningSound, areSoundsAvailable } from '../../utils/soundEffects';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nclass AudioQueueManager {\n  constructor() {\n    this.audioQueue = [];\n    this.isPlaying = false;\n    this.pitchFactor = 0.5;\n    this.onPlayingStateChange = null;\n    makeAutoObservable(this);\n  }\n  setPitchFactor(factor) {\n    this.pitchFactor = factor;\n  }\n  setOnPlayingStateChange(callback) {\n    this.onPlayingStateChange = callback;\n  }\n  addAudioToQueue(audioData) {\n    const wasEmpty = this.audioQueue.length === 0 && !this.isPlaying;\n    this.audioQueue.push(audioData);\n    if (wasEmpty) {\n      this.playNext();\n      if (this.onPlayingStateChange) {\n        this.onPlayingStateChange(true);\n      }\n    }\n  }\n  async playNext() {\n    if (this.isPlaying || this.audioQueue.length === 0) return;\n    this.isPlaying = true;\n    const audioData = this.audioQueue.shift();\n    await this.playAudio(audioData);\n    this.isPlaying = false;\n    if (this.audioQueue.length > 0) {\n      this.playNext();\n    } else if (this.onPlayingStateChange) {\n      this.onPlayingStateChange(false);\n    }\n  }\n  playAudio(audioBuffer) {\n    return new Promise(resolve => {\n      const audioContext = new (window.AudioContext || window.webkitAudioContext)();\n      const binaryString = atob(audioBuffer);\n      const len = binaryString.length;\n      const int16Array = new Int16Array(len / 2);\n      for (let i = 0; i < len; i += 2) {\n        int16Array[i / 2] = binaryString.charCodeAt(i) | binaryString.charCodeAt(i + 1) << 8;\n      }\n      const float32Array = new Float32Array(int16Array.length);\n      for (let i = 0; i < int16Array.length; i++) {\n        float32Array[i] = int16Array[i] / 0x7fff;\n      }\n      const audioBufferObj = audioContext.createBuffer(1, float32Array.length, audioContext.sampleRate);\n      audioBufferObj.copyToChannel(float32Array, 0);\n      const source = audioContext.createBufferSource();\n      source.buffer = audioBufferObj;\n      source.playbackRate.value = this.pitchFactor;\n      source.connect(audioContext.destination);\n      source.onended = () => resolve();\n      source.start(0);\n    });\n  }\n  stopAudio() {\n    const wasPlaying = this.isPlaying || this.audioQueue.length > 0;\n    this.isPlaying = false;\n    this.audioQueue = [];\n    if (wasPlaying && this.onPlayingStateChange) {\n      this.onPlayingStateChange(false);\n    }\n  }\n}\nlet audioContext = null;\nlet mediaStream = null;\nlet processor = null;\nlet analyzerNode = null;\nconst AudioChat = ({\n  voiceEnabled,\n  onVoiceStart,\n  onVoiceStop\n}) => {\n  _s();\n  const audioQueueManager = useMemo(() => new AudioQueueManager(), []);\n  const [aiSpeaking, setAiSpeaking] = useState(false);\n  const [micPaused, setMicPaused] = useState(false);\n  const [soundsLoaded, setSoundsLoaded] = useState(false);\n  const [userSpeaking, setUserSpeaking] = useState(false);\n\n  // Reference for the current response ID and debounce timer\n  const currentResponseIdRef = useRef(\"\");\n  const responseTimerRef = useRef(null);\n\n  // Audio detection settings\n  const silenceDetectionThreshold = 15; // Volume threshold for silence\n  const bufferLength = 50; // Number of samples to keep in the buffer (~1 second at 20ms intervals)\n  const silenceCountThreshold = 45; // Number of samples below threshold to consider silence\n\n  // Audio detection state\n  const volumeBufferRef = useRef(Array(bufferLength).fill(0));\n  const silenceTimerRef = useRef(null);\n  const detectionEnabledRef = useRef(false);\n\n  // Check if sounds are available when component mounts\n  useEffect(() => {\n    setSoundsLoaded(areSoundsAvailable());\n  }, []);\n  const pauseMicrophone = useCallback(() => {\n    if (mediaStream && !micPaused) {\n      mediaStream.getTracks().forEach(track => {\n        track.enabled = false;\n      });\n      setMicPaused(true);\n      console.log('Microphone paused when silence detected');\n\n      // Play the sound when microphone is paused\n      try {\n        playStartListeningSound();\n      } catch (error) {\n        console.error('Failed to play start listening sound:', error);\n      }\n    }\n  }, [micPaused]);\n  const resumeMicrophone = useCallback(() => {\n    if (mediaStream && micPaused) {\n      mediaStream.getTracks().forEach(track => {\n        track.enabled = true;\n      });\n      setMicPaused(false);\n      console.log('Microphone resumed after agent finished speaking');\n\n      // Play the sound when microphone is resumed\n      try {\n        playStopListeningSound();\n      } catch (error) {\n        console.error('Failed to play stop listening sound:', error);\n      }\n    }\n  }, [micPaused]);\n\n  // Analyze audio data to detect silence\n  const analyzeAudio = useCallback(() => {\n    if (!analyzerNode || !detectionEnabledRef.current) return;\n    const dataArray = new Uint8Array(analyzerNode.frequencyBinCount);\n    analyzerNode.getByteFrequencyData(dataArray);\n\n    // Calculate average volume\n    const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;\n\n    // Update buffer (add to front, remove from end)\n    const newBuffer = [average, ...volumeBufferRef.current.slice(0, -1)];\n    volumeBufferRef.current = newBuffer;\n\n    // Count samples below threshold\n    const silenceCount = newBuffer.filter(vol => vol < silenceDetectionThreshold).length;\n\n    // Determine if currently silent based on buffer\n    const isSilent = silenceCount >= silenceCountThreshold;\n    if (isSilent && userSpeaking) {\n      // User was speaking but now is silent\n      console.log('User stopped speaking, silence detected');\n      setUserSpeaking(false);\n\n      // Pause microphone after a brief delay to ensure no false triggers\n      if (silenceTimerRef.current) clearTimeout(silenceTimerRef.current);\n      silenceTimerRef.current = setTimeout(() => {\n        if (!aiSpeaking && !micPaused) {\n          // Only pause if AI isn't speaking\n          console.log('Pausing microphone after silence detection');\n          pauseMicrophone();\n        }\n      }, 700);\n    } else if (!isSilent && !userSpeaking) {\n      // User was silent but now is speaking\n      console.log('User started speaking');\n      setUserSpeaking(true);\n\n      // Cancel any pending silence detection\n      if (silenceTimerRef.current) {\n        clearTimeout(silenceTimerRef.current);\n        silenceTimerRef.current = null;\n      }\n\n      // If microphone was paused, resume it\n      if (micPaused) {\n        console.log('User started speaking, resuming microphone');\n        resumeMicrophone();\n      }\n    }\n\n    // Schedule next analysis\n    requestAnimationFrame(analyzeAudio);\n  }, [pauseMicrophone, resumeMicrophone, userSpeaking, aiSpeaking, micPaused]);\n\n  // Modified: Set AI speaking state and control microphone based on AI speaking\n  useEffect(() => {\n    audioQueueManager.setOnPlayingStateChange(isPlaying => {\n      console.log(`AI speaking state changed to: ${isPlaying}, micPaused: ${micPaused}`);\n      setAiSpeaking(isPlaying);\n      if (isPlaying && !micPaused) {\n        // AI started speaking, pause microphone\n        pauseMicrophone();\n      }\n      // Remove the userSpeaking condition that was preventing microphone resumption\n      else if (!isPlaying && micPaused) {\n        // AI stopped speaking, resume microphone\n        console.log('AI stopped speaking, resuming microphone');\n        resumeMicrophone();\n      }\n    });\n  }, [audioQueueManager, pauseMicrophone, resumeMicrophone, micPaused]);\n  const handleStartVoiceChat = useCallback(async () => {\n    try {\n      playStartListeningSound();\n    } catch (error) {\n      console.error('Failed to play start sound:', error);\n    }\n    onVoiceStart();\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: {\n          sampleRate: 24000,\n          channelCount: 1,\n          echoCancellation: true,\n          noiseSuppression: true,\n          autoGainControl: true\n        }\n      });\n      mediaStream = stream;\n      audioContext = new AudioContext({\n        sampleRate: 24000\n      });\n      const source = audioContext.createMediaStreamSource(stream);\n\n      // Setup analyzer for speech detection\n      analyzerNode = audioContext.createAnalyser();\n      analyzerNode.fftSize = 256;\n      analyzerNode.smoothingTimeConstant = 0.8;\n      source.connect(analyzerNode);\n      processor = audioContext.createScriptProcessor(4096, 1, 1);\n      source.connect(processor);\n      processor.connect(audioContext.destination);\n      processor.onaudioprocess = event => {\n        const inputBuffer = event.inputBuffer;\n        const inputData = inputBuffer.getChannelData(0);\n        const int16Array = new Int16Array(inputData.length);\n        for (let i = 0; i < inputData.length; i++) {\n          int16Array[i] = Math.min(1, Math.max(-1, inputData[i])) * 0x7fff;\n        }\n        const base64String = btoa(String.fromCharCode(...new Uint8Array(int16Array.buffer)));\n        socket.emit('audioInput', base64String);\n      };\n\n      // Start audio analysis\n      detectionEnabledRef.current = true;\n      requestAnimationFrame(analyzeAudio);\n    } catch (error) {\n      console.error('Error accessing microphone:', error);\n    }\n  }, [onVoiceStart, analyzeAudio]);\n  const handleStopVoiceChat = useCallback(() => {\n    try {\n      playStopListeningSound();\n    } catch (error) {\n      console.error('Failed to play stop sound:', error);\n    }\n\n    // Stop audio analysis\n    detectionEnabledRef.current = false;\n    if (silenceTimerRef.current) {\n      clearTimeout(silenceTimerRef.current);\n      silenceTimerRef.current = null;\n    }\n    onVoiceStop();\n    if (audioContext) {\n      audioContext.close();\n      audioContext = null;\n    }\n    if (analyzerNode) {\n      analyzerNode = null;\n    }\n    if (mediaStream) {\n      mediaStream.getTracks().forEach(track => track.stop());\n      mediaStream = null;\n    }\n    if (processor) {\n      processor = null;\n    }\n    setMicPaused(false);\n    setUserSpeaking(false);\n  }, [onVoiceStop]);\n\n  // Improve the audio response handler to ensure microphone resumption\n  useEffect(() => {\n    function handleAudioResponse(data) {\n      console.log('Wojtek AI (audio delta) - response_id:', data.response_id);\n\n      // Update current response ID\n      currentResponseIdRef.current = data.response_id;\n\n      // Clear any existing timer\n      if (responseTimerRef.current) {\n        clearTimeout(responseTimerRef.current);\n      }\n\n      // Set a new timer to detect the end of responses\n      responseTimerRef.current = setTimeout(() => {\n        console.log('Detected last audio response, resuming microphone');\n        if (micPaused) {\n          resumeMicrophone();\n        }\n      }, 1000); // Extend to 1000ms to ensure we catch the true end of the response\n\n      if (data.delta) {\n        audioQueueManager.addAudioToQueue(data.delta);\n      }\n    }\n    if (voiceEnabled) {\n      socket.on('audioResponse', handleAudioResponse);\n    }\n    return () => {\n      socket.off('audioResponse', handleAudioResponse);\n      // Clear timer on cleanup\n      if (responseTimerRef.current) {\n        clearTimeout(responseTimerRef.current);\n      }\n    };\n  }, [voiceEnabled, audioQueueManager, micPaused, resumeMicrophone]);\n\n  // Add a dedicated effect to monitor state changes for debugging\n  useEffect(() => {\n    console.log(`State update - aiSpeaking: ${aiSpeaking}, micPaused: ${micPaused}, userSpeaking: ${userSpeaking}`);\n  }, [aiSpeaking, micPaused, userSpeaking]);\n  useEffect(() => {\n    if (voiceEnabled) {\n      try {\n        playStartListeningSound();\n      } catch (error) {\n        console.error('Failed to play start sound on voice enable:', error);\n      }\n    }\n  }, [voiceEnabled]);\n  if (!voiceEnabled) {\n    return /*#__PURE__*/_jsxDEV(AudioChatIconButton, {\n      onClick: handleStartVoiceChat,\n      src: \"/audio-chat-icon.svg\",\n      alt: \"Audio Chat\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 400,\n      columnNumber: 7\n    }, this);\n  } else {\n    return /*#__PURE__*/_jsxDEV(ChatRuningWrapper, {\n      children: [/*#__PURE__*/_jsxDEV(StopAudioIconButton, {\n        onClick: handleStopVoiceChat,\n        src: \"/arrow-back-icon.svg\",\n        alt: \"Stop Audio Chat\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 409,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(AudioChatRuningIcon, {\n        onClick: handleStopVoiceChat,\n        src: \"/audio-chat-icon-run.svg\",\n        alt: \"Chat runing\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 414,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 408,\n      columnNumber: 7\n    }, this);\n  }\n};\n_s(AudioChat, \"b1fNeurGhWXZtdDgpoANtYXuV2I=\");\n_c = AudioChat;\nexport default AudioChat;\nvar _c;\n$RefreshReg$(_c, \"AudioChat\");","map":{"version":3,"names":["React","useCallback","useEffect","useMemo","useState","useRef","socket","makeAutoObservable","AudioChatIconButton","AudioChatRuningIcon","StopAudioIconButton","ChatRuningWrapper","playStartListeningSound","playStopListeningSound","areSoundsAvailable","jsxDEV","_jsxDEV","AudioQueueManager","constructor","audioQueue","isPlaying","pitchFactor","onPlayingStateChange","setPitchFactor","factor","setOnPlayingStateChange","callback","addAudioToQueue","audioData","wasEmpty","length","push","playNext","shift","playAudio","audioBuffer","Promise","resolve","audioContext","window","AudioContext","webkitAudioContext","binaryString","atob","len","int16Array","Int16Array","i","charCodeAt","float32Array","Float32Array","audioBufferObj","createBuffer","sampleRate","copyToChannel","source","createBufferSource","buffer","playbackRate","value","connect","destination","onended","start","stopAudio","wasPlaying","mediaStream","processor","analyzerNode","AudioChat","voiceEnabled","onVoiceStart","onVoiceStop","_s","audioQueueManager","aiSpeaking","setAiSpeaking","micPaused","setMicPaused","soundsLoaded","setSoundsLoaded","userSpeaking","setUserSpeaking","currentResponseIdRef","responseTimerRef","silenceDetectionThreshold","bufferLength","silenceCountThreshold","volumeBufferRef","Array","fill","silenceTimerRef","detectionEnabledRef","pauseMicrophone","getTracks","forEach","track","enabled","console","log","error","resumeMicrophone","analyzeAudio","current","dataArray","Uint8Array","frequencyBinCount","getByteFrequencyData","average","reduce","sum","newBuffer","slice","silenceCount","filter","vol","isSilent","clearTimeout","setTimeout","requestAnimationFrame","handleStartVoiceChat","stream","navigator","mediaDevices","getUserMedia","audio","channelCount","echoCancellation","noiseSuppression","autoGainControl","createMediaStreamSource","createAnalyser","fftSize","smoothingTimeConstant","createScriptProcessor","onaudioprocess","event","inputBuffer","inputData","getChannelData","Math","min","max","base64String","btoa","String","fromCharCode","emit","handleStopVoiceChat","close","stop","handleAudioResponse","data","response_id","delta","on","off","onClick","src","alt","fileName","_jsxFileName","lineNumber","columnNumber","children","_c","$RefreshReg$"],"sources":["/Users/komasz/Documents/GitHub/ai-voice/frontend/src/components/AudioChat/AudioChat.tsx"],"sourcesContent":["import React, { useCallback, useEffect, useMemo, useState, useRef } from 'react';\nimport { socket } from '../../services/socket';\nimport { makeAutoObservable } from 'mobx';\nimport {\n  AudioChatIconButton,\n  AudioChatRuningIcon,\n  StopAudioIconButton,\n  ChatRuningWrapper,\n} from './AudioChat.styled';\nimport { playStartListeningSound, playStopListeningSound, areSoundsAvailable } from '../../utils/soundEffects';\n\nclass AudioQueueManager {\n  audioQueue: string[] = [];\n  isPlaying = false;\n  pitchFactor = 0.5;\n  onPlayingStateChange: ((isPlaying: boolean) => void) | null = null;\n\n  constructor() {\n    makeAutoObservable(this);\n  }\n\n  setPitchFactor(factor: number) {\n    this.pitchFactor = factor;\n  }\n\n  setOnPlayingStateChange(callback: (isPlaying: boolean) => void) {\n    this.onPlayingStateChange = callback;\n  }\n\n  addAudioToQueue(audioData: string) {\n    const wasEmpty = this.audioQueue.length === 0 && !this.isPlaying;\n    this.audioQueue.push(audioData);\n\n    if (wasEmpty) {\n      this.playNext();\n      if (this.onPlayingStateChange) {\n        this.onPlayingStateChange(true);\n      }\n    }\n  }\n\n  async playNext() {\n    if (this.isPlaying || this.audioQueue.length === 0) return;\n\n    this.isPlaying = true;\n    const audioData = this.audioQueue.shift() as string;\n    await this.playAudio(audioData);\n\n    this.isPlaying = false;\n\n    if (this.audioQueue.length > 0) {\n      this.playNext();\n    } else if (this.onPlayingStateChange) {\n      this.onPlayingStateChange(false);\n    }\n  }\n\n  playAudio(audioBuffer: string): Promise<void> {\n    return new Promise(resolve => {\n      const audioContext = new (window.AudioContext ||\n        (window as any).webkitAudioContext)();\n\n      const binaryString = atob(audioBuffer);\n      const len = binaryString.length;\n      const int16Array = new Int16Array(len / 2);\n\n      for (let i = 0; i < len; i += 2) {\n        int16Array[i / 2] =\n          binaryString.charCodeAt(i) | (binaryString.charCodeAt(i + 1) << 8);\n      }\n\n      const float32Array = new Float32Array(int16Array.length);\n      for (let i = 0; i < int16Array.length; i++) {\n        float32Array[i] = int16Array[i] / 0x7fff;\n      }\n\n      const audioBufferObj = audioContext.createBuffer(\n        1,\n        float32Array.length,\n        audioContext.sampleRate,\n      );\n      audioBufferObj.copyToChannel(float32Array, 0);\n\n      const source = audioContext.createBufferSource();\n      source.buffer = audioBufferObj;\n      source.playbackRate.value = this.pitchFactor;\n\n      source.connect(audioContext.destination);\n      source.onended = () => resolve();\n      source.start(0);\n    });\n  }\n\n  stopAudio() {\n    const wasPlaying = this.isPlaying || this.audioQueue.length > 0;\n    this.isPlaying = false;\n    this.audioQueue = [];\n\n    if (wasPlaying && this.onPlayingStateChange) {\n      this.onPlayingStateChange(false);\n    }\n  }\n}\n\ninterface AudioChatProps {\n  voiceEnabled: boolean;\n  onVoiceStart: () => void;\n  onVoiceStop: () => void;\n}\n\nlet audioContext: AudioContext | null = null;\nlet mediaStream: MediaStream | null = null;\nlet processor: ScriptProcessorNode | null = null;\nlet analyzerNode: AnalyserNode | null = null;\n\nconst AudioChat: React.FC<AudioChatProps> = ({\n  voiceEnabled,\n  onVoiceStart,\n  onVoiceStop,\n}) => {\n  const audioQueueManager = useMemo(() => new AudioQueueManager(), []);\n  const [aiSpeaking, setAiSpeaking] = useState(false);\n  const [micPaused, setMicPaused] = useState(false);\n  const [soundsLoaded, setSoundsLoaded] = useState(false);\n  const [userSpeaking, setUserSpeaking] = useState(false);\n\n  // Reference for the current response ID and debounce timer\n  const currentResponseIdRef = useRef<string>(\"\");\n  const responseTimerRef = useRef<NodeJS.Timeout | null>(null);\n  \n  // Audio detection settings\n  const silenceDetectionThreshold = 15; // Volume threshold for silence\n  const bufferLength = 50; // Number of samples to keep in the buffer (~1 second at 20ms intervals)\n  const silenceCountThreshold = 45; // Number of samples below threshold to consider silence\n  \n  // Audio detection state\n  const volumeBufferRef = useRef<number[]>(Array(bufferLength).fill(0));\n  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null);\n  const detectionEnabledRef = useRef<boolean>(false);\n\n  // Check if sounds are available when component mounts\n  useEffect(() => {\n    setSoundsLoaded(areSoundsAvailable());\n  }, []);\n\n  const pauseMicrophone = useCallback(() => {\n    if (mediaStream && !micPaused) {\n      mediaStream.getTracks().forEach(track => {\n        track.enabled = false;\n      });\n      setMicPaused(true);\n      console.log('Microphone paused when silence detected');\n      \n      // Play the sound when microphone is paused\n      try {\n        playStartListeningSound();\n      } catch (error) {\n        console.error('Failed to play start listening sound:', error);\n      }\n    }\n  }, [micPaused]);\n\n  const resumeMicrophone = useCallback(() => {\n    if (mediaStream && micPaused) {\n      mediaStream.getTracks().forEach(track => {\n        track.enabled = true;\n      });\n      setMicPaused(false);\n      console.log('Microphone resumed after agent finished speaking');\n      \n      // Play the sound when microphone is resumed\n      try {\n        playStopListeningSound();\n      } catch (error) {\n        console.error('Failed to play stop listening sound:', error);\n      }\n    }\n  }, [micPaused]);\n\n  // Analyze audio data to detect silence\n  const analyzeAudio = useCallback(() => {\n    if (!analyzerNode || !detectionEnabledRef.current) return;\n    \n    const dataArray = new Uint8Array(analyzerNode.frequencyBinCount);\n    analyzerNode.getByteFrequencyData(dataArray);\n    \n    // Calculate average volume\n    const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;\n    \n    // Update buffer (add to front, remove from end)\n    const newBuffer = [average, ...volumeBufferRef.current.slice(0, -1)];\n    volumeBufferRef.current = newBuffer;\n    \n    // Count samples below threshold\n    const silenceCount = newBuffer.filter(vol => vol < silenceDetectionThreshold).length;\n    \n    // Determine if currently silent based on buffer\n    const isSilent = silenceCount >= silenceCountThreshold;\n    \n    if (isSilent && userSpeaking) {\n      // User was speaking but now is silent\n      console.log('User stopped speaking, silence detected');\n      setUserSpeaking(false);\n      \n      // Pause microphone after a brief delay to ensure no false triggers\n      if (silenceTimerRef.current) clearTimeout(silenceTimerRef.current);\n      silenceTimerRef.current = setTimeout(() => {\n        if (!aiSpeaking && !micPaused) {  // Only pause if AI isn't speaking\n          console.log('Pausing microphone after silence detection');\n          pauseMicrophone();\n        }\n      }, 700);\n    } else if (!isSilent && !userSpeaking) {\n      // User was silent but now is speaking\n      console.log('User started speaking');\n      setUserSpeaking(true);\n      \n      // Cancel any pending silence detection\n      if (silenceTimerRef.current) {\n        clearTimeout(silenceTimerRef.current);\n        silenceTimerRef.current = null;\n      }\n      \n      // If microphone was paused, resume it\n      if (micPaused) {\n        console.log('User started speaking, resuming microphone');\n        resumeMicrophone();\n      }\n    }\n    \n    // Schedule next analysis\n    requestAnimationFrame(analyzeAudio);\n  }, [pauseMicrophone, resumeMicrophone, userSpeaking, aiSpeaking, micPaused]);\n\n  // Modified: Set AI speaking state and control microphone based on AI speaking\n  useEffect(() => {\n    audioQueueManager.setOnPlayingStateChange((isPlaying) => {\n      console.log(`AI speaking state changed to: ${isPlaying}, micPaused: ${micPaused}`);\n      setAiSpeaking(isPlaying);\n      \n      if (isPlaying && !micPaused) {\n        // AI started speaking, pause microphone\n        pauseMicrophone();\n      } \n      // Remove the userSpeaking condition that was preventing microphone resumption\n      else if (!isPlaying && micPaused) {\n        // AI stopped speaking, resume microphone\n        console.log('AI stopped speaking, resuming microphone');\n        resumeMicrophone();\n      }\n    });\n  }, [audioQueueManager, pauseMicrophone, resumeMicrophone, micPaused]);\n\n  const handleStartVoiceChat = useCallback(async () => {\n    try {\n      playStartListeningSound();\n    } catch (error) {\n      console.error('Failed to play start sound:', error);\n    }\n\n    onVoiceStart();\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: {\n          sampleRate: 24000,\n          channelCount: 1,\n          echoCancellation: true,\n          noiseSuppression: true,\n          autoGainControl: true,\n        },\n      });\n      mediaStream = stream;\n\n      audioContext = new AudioContext({ sampleRate: 24000 });\n      const source = audioContext.createMediaStreamSource(stream);\n      \n      // Setup analyzer for speech detection\n      analyzerNode = audioContext.createAnalyser();\n      analyzerNode.fftSize = 256;\n      analyzerNode.smoothingTimeConstant = 0.8;\n      source.connect(analyzerNode);\n      \n      processor = audioContext.createScriptProcessor(4096, 1, 1);\n      source.connect(processor);\n      processor.connect(audioContext.destination);\n\n      processor.onaudioprocess = event => {\n        const inputBuffer = event.inputBuffer;\n        const inputData = inputBuffer.getChannelData(0);\n\n        const int16Array = new Int16Array(inputData.length);\n        for (let i = 0; i < inputData.length; i++) {\n          int16Array[i] = Math.min(1, Math.max(-1, inputData[i])) * 0x7fff;\n        }\n\n        const base64String = btoa(\n          String.fromCharCode(...new Uint8Array(int16Array.buffer)),\n        );\n        socket.emit('audioInput', base64String);\n      };\n      \n      // Start audio analysis\n      detectionEnabledRef.current = true;\n      requestAnimationFrame(analyzeAudio);\n      \n    } catch (error) {\n      console.error('Error accessing microphone:', error);\n    }\n  }, [onVoiceStart, analyzeAudio]);\n\n  const handleStopVoiceChat = useCallback(() => {\n    try {\n      playStopListeningSound();\n    } catch (error) {\n      console.error('Failed to play stop sound:', error);\n    }\n\n    // Stop audio analysis\n    detectionEnabledRef.current = false;\n    if (silenceTimerRef.current) {\n      clearTimeout(silenceTimerRef.current);\n      silenceTimerRef.current = null;\n    }\n\n    onVoiceStop();\n    if (audioContext) {\n      audioContext.close();\n      audioContext = null;\n    }\n    if (analyzerNode) {\n      analyzerNode = null;\n    }\n    if (mediaStream) {\n      mediaStream.getTracks().forEach(track => track.stop());\n      mediaStream = null;\n    }\n    if (processor) {\n      processor = null;\n    }\n    setMicPaused(false);\n    setUserSpeaking(false);\n  }, [onVoiceStop]);\n\n  // Improve the audio response handler to ensure microphone resumption\n  useEffect(() => {\n    function handleAudioResponse(data: any) {\n      console.log('Wojtek AI (audio delta) - response_id:', data.response_id);\n      \n      // Update current response ID\n      currentResponseIdRef.current = data.response_id;\n      \n      // Clear any existing timer\n      if (responseTimerRef.current) {\n        clearTimeout(responseTimerRef.current);\n      }\n      \n      // Set a new timer to detect the end of responses\n      responseTimerRef.current = setTimeout(() => {\n        console.log('Detected last audio response, resuming microphone');\n        if (micPaused) {\n          resumeMicrophone();\n        }\n      }, 1000); // Extend to 1000ms to ensure we catch the true end of the response\n      \n      if (data.delta) {\n        audioQueueManager.addAudioToQueue(data.delta);\n      }\n    }\n    \n    if (voiceEnabled) {\n      socket.on('audioResponse', handleAudioResponse);\n    }\n    \n    return () => {\n      socket.off('audioResponse', handleAudioResponse);\n      // Clear timer on cleanup\n      if (responseTimerRef.current) {\n        clearTimeout(responseTimerRef.current);\n      }\n    };\n  }, [voiceEnabled, audioQueueManager, micPaused, resumeMicrophone]);\n\n  // Add a dedicated effect to monitor state changes for debugging\n  useEffect(() => {\n    console.log(`State update - aiSpeaking: ${aiSpeaking}, micPaused: ${micPaused}, userSpeaking: ${userSpeaking}`);\n  }, [aiSpeaking, micPaused, userSpeaking]);\n\n  useEffect(() => {\n    if (voiceEnabled) {\n      try {\n        playStartListeningSound();\n      } catch (error) {\n        console.error('Failed to play start sound on voice enable:', error);\n      }\n    }\n  }, [voiceEnabled]);\n\n  if (!voiceEnabled) {\n    return (\n      <AudioChatIconButton\n        onClick={handleStartVoiceChat}\n        src=\"/audio-chat-icon.svg\"\n        alt=\"Audio Chat\"\n      />\n    );\n  } else {\n    return (\n      <ChatRuningWrapper>\n        <StopAudioIconButton\n          onClick={handleStopVoiceChat}\n          src=\"/arrow-back-icon.svg\"\n          alt=\"Stop Audio Chat\"\n        />\n        <AudioChatRuningIcon\n          onClick={handleStopVoiceChat}\n          src=\"/audio-chat-icon-run.svg\"\n          alt=\"Chat runing\"\n        />\n      </ChatRuningWrapper>\n    );\n  }\n};\n\nexport default AudioChat;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,WAAW,EAAEC,SAAS,EAAEC,OAAO,EAAEC,QAAQ,EAAEC,MAAM,QAAQ,OAAO;AAChF,SAASC,MAAM,QAAQ,uBAAuB;AAC9C,SAASC,kBAAkB,QAAQ,MAAM;AACzC,SACEC,mBAAmB,EACnBC,mBAAmB,EACnBC,mBAAmB,EACnBC,iBAAiB,QACZ,oBAAoB;AAC3B,SAASC,uBAAuB,EAAEC,sBAAsB,EAAEC,kBAAkB,QAAQ,0BAA0B;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE/G,MAAMC,iBAAiB,CAAC;EAMtBC,WAAWA,CAAA,EAAG;IAAA,KALdC,UAAU,GAAa,EAAE;IAAA,KACzBC,SAAS,GAAG,KAAK;IAAA,KACjBC,WAAW,GAAG,GAAG;IAAA,KACjBC,oBAAoB,GAA0C,IAAI;IAGhEf,kBAAkB,CAAC,IAAI,CAAC;EAC1B;EAEAgB,cAAcA,CAACC,MAAc,EAAE;IAC7B,IAAI,CAACH,WAAW,GAAGG,MAAM;EAC3B;EAEAC,uBAAuBA,CAACC,QAAsC,EAAE;IAC9D,IAAI,CAACJ,oBAAoB,GAAGI,QAAQ;EACtC;EAEAC,eAAeA,CAACC,SAAiB,EAAE;IACjC,MAAMC,QAAQ,GAAG,IAAI,CAACV,UAAU,CAACW,MAAM,KAAK,CAAC,IAAI,CAAC,IAAI,CAACV,SAAS;IAChE,IAAI,CAACD,UAAU,CAACY,IAAI,CAACH,SAAS,CAAC;IAE/B,IAAIC,QAAQ,EAAE;MACZ,IAAI,CAACG,QAAQ,CAAC,CAAC;MACf,IAAI,IAAI,CAACV,oBAAoB,EAAE;QAC7B,IAAI,CAACA,oBAAoB,CAAC,IAAI,CAAC;MACjC;IACF;EACF;EAEA,MAAMU,QAAQA,CAAA,EAAG;IACf,IAAI,IAAI,CAACZ,SAAS,IAAI,IAAI,CAACD,UAAU,CAACW,MAAM,KAAK,CAAC,EAAE;IAEpD,IAAI,CAACV,SAAS,GAAG,IAAI;IACrB,MAAMQ,SAAS,GAAG,IAAI,CAACT,UAAU,CAACc,KAAK,CAAC,CAAW;IACnD,MAAM,IAAI,CAACC,SAAS,CAACN,SAAS,CAAC;IAE/B,IAAI,CAACR,SAAS,GAAG,KAAK;IAEtB,IAAI,IAAI,CAACD,UAAU,CAACW,MAAM,GAAG,CAAC,EAAE;MAC9B,IAAI,CAACE,QAAQ,CAAC,CAAC;IACjB,CAAC,MAAM,IAAI,IAAI,CAACV,oBAAoB,EAAE;MACpC,IAAI,CAACA,oBAAoB,CAAC,KAAK,CAAC;IAClC;EACF;EAEAY,SAASA,CAACC,WAAmB,EAAiB;IAC5C,OAAO,IAAIC,OAAO,CAACC,OAAO,IAAI;MAC5B,MAAMC,YAAY,GAAG,KAAKC,MAAM,CAACC,YAAY,IAC1CD,MAAM,CAASE,kBAAkB,EAAE,CAAC;MAEvC,MAAMC,YAAY,GAAGC,IAAI,CAACR,WAAW,CAAC;MACtC,MAAMS,GAAG,GAAGF,YAAY,CAACZ,MAAM;MAC/B,MAAMe,UAAU,GAAG,IAAIC,UAAU,CAACF,GAAG,GAAG,CAAC,CAAC;MAE1C,KAAK,IAAIG,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGH,GAAG,EAAEG,CAAC,IAAI,CAAC,EAAE;QAC/BF,UAAU,CAACE,CAAC,GAAG,CAAC,CAAC,GACfL,YAAY,CAACM,UAAU,CAACD,CAAC,CAAC,GAAIL,YAAY,CAACM,UAAU,CAACD,CAAC,GAAG,CAAC,CAAC,IAAI,CAAE;MACtE;MAEA,MAAME,YAAY,GAAG,IAAIC,YAAY,CAACL,UAAU,CAACf,MAAM,CAAC;MACxD,KAAK,IAAIiB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,UAAU,CAACf,MAAM,EAAEiB,CAAC,EAAE,EAAE;QAC1CE,YAAY,CAACF,CAAC,CAAC,GAAGF,UAAU,CAACE,CAAC,CAAC,GAAG,MAAM;MAC1C;MAEA,MAAMI,cAAc,GAAGb,YAAY,CAACc,YAAY,CAC9C,CAAC,EACDH,YAAY,CAACnB,MAAM,EACnBQ,YAAY,CAACe,UACf,CAAC;MACDF,cAAc,CAACG,aAAa,CAACL,YAAY,EAAE,CAAC,CAAC;MAE7C,MAAMM,MAAM,GAAGjB,YAAY,CAACkB,kBAAkB,CAAC,CAAC;MAChDD,MAAM,CAACE,MAAM,GAAGN,cAAc;MAC9BI,MAAM,CAACG,YAAY,CAACC,KAAK,GAAG,IAAI,CAACtC,WAAW;MAE5CkC,MAAM,CAACK,OAAO,CAACtB,YAAY,CAACuB,WAAW,CAAC;MACxCN,MAAM,CAACO,OAAO,GAAG,MAAMzB,OAAO,CAAC,CAAC;MAChCkB,MAAM,CAACQ,KAAK,CAAC,CAAC,CAAC;IACjB,CAAC,CAAC;EACJ;EAEAC,SAASA,CAAA,EAAG;IACV,MAAMC,UAAU,GAAG,IAAI,CAAC7C,SAAS,IAAI,IAAI,CAACD,UAAU,CAACW,MAAM,GAAG,CAAC;IAC/D,IAAI,CAACV,SAAS,GAAG,KAAK;IACtB,IAAI,CAACD,UAAU,GAAG,EAAE;IAEpB,IAAI8C,UAAU,IAAI,IAAI,CAAC3C,oBAAoB,EAAE;MAC3C,IAAI,CAACA,oBAAoB,CAAC,KAAK,CAAC;IAClC;EACF;AACF;AAQA,IAAIgB,YAAiC,GAAG,IAAI;AAC5C,IAAI4B,WAA+B,GAAG,IAAI;AAC1C,IAAIC,SAAqC,GAAG,IAAI;AAChD,IAAIC,YAAiC,GAAG,IAAI;AAE5C,MAAMC,SAAmC,GAAGA,CAAC;EAC3CC,YAAY;EACZC,YAAY;EACZC;AACF,CAAC,KAAK;EAAAC,EAAA;EACJ,MAAMC,iBAAiB,GAAGvE,OAAO,CAAC,MAAM,IAAIc,iBAAiB,CAAC,CAAC,EAAE,EAAE,CAAC;EACpE,MAAM,CAAC0D,UAAU,EAAEC,aAAa,CAAC,GAAGxE,QAAQ,CAAC,KAAK,CAAC;EACnD,MAAM,CAACyE,SAAS,EAAEC,YAAY,CAAC,GAAG1E,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAM,CAAC2E,YAAY,EAAEC,eAAe,CAAC,GAAG5E,QAAQ,CAAC,KAAK,CAAC;EACvD,MAAM,CAAC6E,YAAY,EAAEC,eAAe,CAAC,GAAG9E,QAAQ,CAAC,KAAK,CAAC;;EAEvD;EACA,MAAM+E,oBAAoB,GAAG9E,MAAM,CAAS,EAAE,CAAC;EAC/C,MAAM+E,gBAAgB,GAAG/E,MAAM,CAAwB,IAAI,CAAC;;EAE5D;EACA,MAAMgF,yBAAyB,GAAG,EAAE,CAAC,CAAC;EACtC,MAAMC,YAAY,GAAG,EAAE,CAAC,CAAC;EACzB,MAAMC,qBAAqB,GAAG,EAAE,CAAC,CAAC;;EAElC;EACA,MAAMC,eAAe,GAAGnF,MAAM,CAAWoF,KAAK,CAACH,YAAY,CAAC,CAACI,IAAI,CAAC,CAAC,CAAC,CAAC;EACrE,MAAMC,eAAe,GAAGtF,MAAM,CAAwB,IAAI,CAAC;EAC3D,MAAMuF,mBAAmB,GAAGvF,MAAM,CAAU,KAAK,CAAC;;EAElD;EACAH,SAAS,CAAC,MAAM;IACd8E,eAAe,CAAClE,kBAAkB,CAAC,CAAC,CAAC;EACvC,CAAC,EAAE,EAAE,CAAC;EAEN,MAAM+E,eAAe,GAAG5F,WAAW,CAAC,MAAM;IACxC,IAAIiE,WAAW,IAAI,CAACW,SAAS,EAAE;MAC7BX,WAAW,CAAC4B,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAI;QACvCA,KAAK,CAACC,OAAO,GAAG,KAAK;MACvB,CAAC,CAAC;MACFnB,YAAY,CAAC,IAAI,CAAC;MAClBoB,OAAO,CAACC,GAAG,CAAC,yCAAyC,CAAC;;MAEtD;MACA,IAAI;QACFvF,uBAAuB,CAAC,CAAC;MAC3B,CAAC,CAAC,OAAOwF,KAAK,EAAE;QACdF,OAAO,CAACE,KAAK,CAAC,uCAAuC,EAAEA,KAAK,CAAC;MAC/D;IACF;EACF,CAAC,EAAE,CAACvB,SAAS,CAAC,CAAC;EAEf,MAAMwB,gBAAgB,GAAGpG,WAAW,CAAC,MAAM;IACzC,IAAIiE,WAAW,IAAIW,SAAS,EAAE;MAC5BX,WAAW,CAAC4B,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAI;QACvCA,KAAK,CAACC,OAAO,GAAG,IAAI;MACtB,CAAC,CAAC;MACFnB,YAAY,CAAC,KAAK,CAAC;MACnBoB,OAAO,CAACC,GAAG,CAAC,kDAAkD,CAAC;;MAE/D;MACA,IAAI;QACFtF,sBAAsB,CAAC,CAAC;MAC1B,CAAC,CAAC,OAAOuF,KAAK,EAAE;QACdF,OAAO,CAACE,KAAK,CAAC,sCAAsC,EAAEA,KAAK,CAAC;MAC9D;IACF;EACF,CAAC,EAAE,CAACvB,SAAS,CAAC,CAAC;;EAEf;EACA,MAAMyB,YAAY,GAAGrG,WAAW,CAAC,MAAM;IACrC,IAAI,CAACmE,YAAY,IAAI,CAACwB,mBAAmB,CAACW,OAAO,EAAE;IAEnD,MAAMC,SAAS,GAAG,IAAIC,UAAU,CAACrC,YAAY,CAACsC,iBAAiB,CAAC;IAChEtC,YAAY,CAACuC,oBAAoB,CAACH,SAAS,CAAC;;IAE5C;IACA,MAAMI,OAAO,GAAGJ,SAAS,CAACK,MAAM,CAAC,CAACC,GAAG,EAAEnD,KAAK,KAAKmD,GAAG,GAAGnD,KAAK,EAAE,CAAC,CAAC,GAAG6C,SAAS,CAAC1E,MAAM;;IAEnF;IACA,MAAMiF,SAAS,GAAG,CAACH,OAAO,EAAE,GAAGpB,eAAe,CAACe,OAAO,CAACS,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IACpExB,eAAe,CAACe,OAAO,GAAGQ,SAAS;;IAEnC;IACA,MAAME,YAAY,GAAGF,SAAS,CAACG,MAAM,CAACC,GAAG,IAAIA,GAAG,GAAG9B,yBAAyB,CAAC,CAACvD,MAAM;;IAEpF;IACA,MAAMsF,QAAQ,GAAGH,YAAY,IAAI1B,qBAAqB;IAEtD,IAAI6B,QAAQ,IAAInC,YAAY,EAAE;MAC5B;MACAiB,OAAO,CAACC,GAAG,CAAC,yCAAyC,CAAC;MACtDjB,eAAe,CAAC,KAAK,CAAC;;MAEtB;MACA,IAAIS,eAAe,CAACY,OAAO,EAAEc,YAAY,CAAC1B,eAAe,CAACY,OAAO,CAAC;MAClEZ,eAAe,CAACY,OAAO,GAAGe,UAAU,CAAC,MAAM;QACzC,IAAI,CAAC3C,UAAU,IAAI,CAACE,SAAS,EAAE;UAAG;UAChCqB,OAAO,CAACC,GAAG,CAAC,4CAA4C,CAAC;UACzDN,eAAe,CAAC,CAAC;QACnB;MACF,CAAC,EAAE,GAAG,CAAC;IACT,CAAC,MAAM,IAAI,CAACuB,QAAQ,IAAI,CAACnC,YAAY,EAAE;MACrC;MACAiB,OAAO,CAACC,GAAG,CAAC,uBAAuB,CAAC;MACpCjB,eAAe,CAAC,IAAI,CAAC;;MAErB;MACA,IAAIS,eAAe,CAACY,OAAO,EAAE;QAC3Bc,YAAY,CAAC1B,eAAe,CAACY,OAAO,CAAC;QACrCZ,eAAe,CAACY,OAAO,GAAG,IAAI;MAChC;;MAEA;MACA,IAAI1B,SAAS,EAAE;QACbqB,OAAO,CAACC,GAAG,CAAC,4CAA4C,CAAC;QACzDE,gBAAgB,CAAC,CAAC;MACpB;IACF;;IAEA;IACAkB,qBAAqB,CAACjB,YAAY,CAAC;EACrC,CAAC,EAAE,CAACT,eAAe,EAAEQ,gBAAgB,EAAEpB,YAAY,EAAEN,UAAU,EAAEE,SAAS,CAAC,CAAC;;EAE5E;EACA3E,SAAS,CAAC,MAAM;IACdwE,iBAAiB,CAACjD,uBAAuB,CAAEL,SAAS,IAAK;MACvD8E,OAAO,CAACC,GAAG,CAAC,iCAAiC/E,SAAS,gBAAgByD,SAAS,EAAE,CAAC;MAClFD,aAAa,CAACxD,SAAS,CAAC;MAExB,IAAIA,SAAS,IAAI,CAACyD,SAAS,EAAE;QAC3B;QACAgB,eAAe,CAAC,CAAC;MACnB;MACA;MAAA,KACK,IAAI,CAACzE,SAAS,IAAIyD,SAAS,EAAE;QAChC;QACAqB,OAAO,CAACC,GAAG,CAAC,0CAA0C,CAAC;QACvDE,gBAAgB,CAAC,CAAC;MACpB;IACF,CAAC,CAAC;EACJ,CAAC,EAAE,CAAC3B,iBAAiB,EAAEmB,eAAe,EAAEQ,gBAAgB,EAAExB,SAAS,CAAC,CAAC;EAErE,MAAM2C,oBAAoB,GAAGvH,WAAW,CAAC,YAAY;IACnD,IAAI;MACFW,uBAAuB,CAAC,CAAC;IAC3B,CAAC,CAAC,OAAOwF,KAAK,EAAE;MACdF,OAAO,CAACE,KAAK,CAAC,6BAA6B,EAAEA,KAAK,CAAC;IACrD;IAEA7B,YAAY,CAAC,CAAC;IACd,IAAI;MACF,MAAMkD,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QACvDC,KAAK,EAAE;UACLxE,UAAU,EAAE,KAAK;UACjByE,YAAY,EAAE,CAAC;UACfC,gBAAgB,EAAE,IAAI;UACtBC,gBAAgB,EAAE,IAAI;UACtBC,eAAe,EAAE;QACnB;MACF,CAAC,CAAC;MACF/D,WAAW,GAAGuD,MAAM;MAEpBnF,YAAY,GAAG,IAAIE,YAAY,CAAC;QAAEa,UAAU,EAAE;MAAM,CAAC,CAAC;MACtD,MAAME,MAAM,GAAGjB,YAAY,CAAC4F,uBAAuB,CAACT,MAAM,CAAC;;MAE3D;MACArD,YAAY,GAAG9B,YAAY,CAAC6F,cAAc,CAAC,CAAC;MAC5C/D,YAAY,CAACgE,OAAO,GAAG,GAAG;MAC1BhE,YAAY,CAACiE,qBAAqB,GAAG,GAAG;MACxC9E,MAAM,CAACK,OAAO,CAACQ,YAAY,CAAC;MAE5BD,SAAS,GAAG7B,YAAY,CAACgG,qBAAqB,CAAC,IAAI,EAAE,CAAC,EAAE,CAAC,CAAC;MAC1D/E,MAAM,CAACK,OAAO,CAACO,SAAS,CAAC;MACzBA,SAAS,CAACP,OAAO,CAACtB,YAAY,CAACuB,WAAW,CAAC;MAE3CM,SAAS,CAACoE,cAAc,GAAGC,KAAK,IAAI;QAClC,MAAMC,WAAW,GAAGD,KAAK,CAACC,WAAW;QACrC,MAAMC,SAAS,GAAGD,WAAW,CAACE,cAAc,CAAC,CAAC,CAAC;QAE/C,MAAM9F,UAAU,GAAG,IAAIC,UAAU,CAAC4F,SAAS,CAAC5G,MAAM,CAAC;QACnD,KAAK,IAAIiB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG2F,SAAS,CAAC5G,MAAM,EAAEiB,CAAC,EAAE,EAAE;UACzCF,UAAU,CAACE,CAAC,CAAC,GAAG6F,IAAI,CAACC,GAAG,CAAC,CAAC,EAAED,IAAI,CAACE,GAAG,CAAC,CAAC,CAAC,EAAEJ,SAAS,CAAC3F,CAAC,CAAC,CAAC,CAAC,GAAG,MAAM;QAClE;QAEA,MAAMgG,YAAY,GAAGC,IAAI,CACvBC,MAAM,CAACC,YAAY,CAAC,GAAG,IAAIzC,UAAU,CAAC5D,UAAU,CAACY,MAAM,CAAC,CAC1D,CAAC;QACDnD,MAAM,CAAC6I,IAAI,CAAC,YAAY,EAAEJ,YAAY,CAAC;MACzC,CAAC;;MAED;MACAnD,mBAAmB,CAACW,OAAO,GAAG,IAAI;MAClCgB,qBAAqB,CAACjB,YAAY,CAAC;IAErC,CAAC,CAAC,OAAOF,KAAK,EAAE;MACdF,OAAO,CAACE,KAAK,CAAC,6BAA6B,EAAEA,KAAK,CAAC;IACrD;EACF,CAAC,EAAE,CAAC7B,YAAY,EAAE+B,YAAY,CAAC,CAAC;EAEhC,MAAM8C,mBAAmB,GAAGnJ,WAAW,CAAC,MAAM;IAC5C,IAAI;MACFY,sBAAsB,CAAC,CAAC;IAC1B,CAAC,CAAC,OAAOuF,KAAK,EAAE;MACdF,OAAO,CAACE,KAAK,CAAC,4BAA4B,EAAEA,KAAK,CAAC;IACpD;;IAEA;IACAR,mBAAmB,CAACW,OAAO,GAAG,KAAK;IACnC,IAAIZ,eAAe,CAACY,OAAO,EAAE;MAC3Bc,YAAY,CAAC1B,eAAe,CAACY,OAAO,CAAC;MACrCZ,eAAe,CAACY,OAAO,GAAG,IAAI;IAChC;IAEA/B,WAAW,CAAC,CAAC;IACb,IAAIlC,YAAY,EAAE;MAChBA,YAAY,CAAC+G,KAAK,CAAC,CAAC;MACpB/G,YAAY,GAAG,IAAI;IACrB;IACA,IAAI8B,YAAY,EAAE;MAChBA,YAAY,GAAG,IAAI;IACrB;IACA,IAAIF,WAAW,EAAE;MACfA,WAAW,CAAC4B,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACsD,IAAI,CAAC,CAAC,CAAC;MACtDpF,WAAW,GAAG,IAAI;IACpB;IACA,IAAIC,SAAS,EAAE;MACbA,SAAS,GAAG,IAAI;IAClB;IACAW,YAAY,CAAC,KAAK,CAAC;IACnBI,eAAe,CAAC,KAAK,CAAC;EACxB,CAAC,EAAE,CAACV,WAAW,CAAC,CAAC;;EAEjB;EACAtE,SAAS,CAAC,MAAM;IACd,SAASqJ,mBAAmBA,CAACC,IAAS,EAAE;MACtCtD,OAAO,CAACC,GAAG,CAAC,wCAAwC,EAAEqD,IAAI,CAACC,WAAW,CAAC;;MAEvE;MACAtE,oBAAoB,CAACoB,OAAO,GAAGiD,IAAI,CAACC,WAAW;;MAE/C;MACA,IAAIrE,gBAAgB,CAACmB,OAAO,EAAE;QAC5Bc,YAAY,CAACjC,gBAAgB,CAACmB,OAAO,CAAC;MACxC;;MAEA;MACAnB,gBAAgB,CAACmB,OAAO,GAAGe,UAAU,CAAC,MAAM;QAC1CpB,OAAO,CAACC,GAAG,CAAC,mDAAmD,CAAC;QAChE,IAAItB,SAAS,EAAE;UACbwB,gBAAgB,CAAC,CAAC;QACpB;MACF,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC;;MAEV,IAAImD,IAAI,CAACE,KAAK,EAAE;QACdhF,iBAAiB,CAAC/C,eAAe,CAAC6H,IAAI,CAACE,KAAK,CAAC;MAC/C;IACF;IAEA,IAAIpF,YAAY,EAAE;MAChBhE,MAAM,CAACqJ,EAAE,CAAC,eAAe,EAAEJ,mBAAmB,CAAC;IACjD;IAEA,OAAO,MAAM;MACXjJ,MAAM,CAACsJ,GAAG,CAAC,eAAe,EAAEL,mBAAmB,CAAC;MAChD;MACA,IAAInE,gBAAgB,CAACmB,OAAO,EAAE;QAC5Bc,YAAY,CAACjC,gBAAgB,CAACmB,OAAO,CAAC;MACxC;IACF,CAAC;EACH,CAAC,EAAE,CAACjC,YAAY,EAAEI,iBAAiB,EAAEG,SAAS,EAAEwB,gBAAgB,CAAC,CAAC;;EAElE;EACAnG,SAAS,CAAC,MAAM;IACdgG,OAAO,CAACC,GAAG,CAAC,8BAA8BxB,UAAU,gBAAgBE,SAAS,mBAAmBI,YAAY,EAAE,CAAC;EACjH,CAAC,EAAE,CAACN,UAAU,EAAEE,SAAS,EAAEI,YAAY,CAAC,CAAC;EAEzC/E,SAAS,CAAC,MAAM;IACd,IAAIoE,YAAY,EAAE;MAChB,IAAI;QACF1D,uBAAuB,CAAC,CAAC;MAC3B,CAAC,CAAC,OAAOwF,KAAK,EAAE;QACdF,OAAO,CAACE,KAAK,CAAC,6CAA6C,EAAEA,KAAK,CAAC;MACrE;IACF;EACF,CAAC,EAAE,CAAC9B,YAAY,CAAC,CAAC;EAElB,IAAI,CAACA,YAAY,EAAE;IACjB,oBACEtD,OAAA,CAACR,mBAAmB;MAClBqJ,OAAO,EAAErC,oBAAqB;MAC9BsC,GAAG,EAAC,sBAAsB;MAC1BC,GAAG,EAAC;IAAY;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACjB,CAAC;EAEN,CAAC,MAAM;IACL,oBACEnJ,OAAA,CAACL,iBAAiB;MAAAyJ,QAAA,gBAChBpJ,OAAA,CAACN,mBAAmB;QAClBmJ,OAAO,EAAET,mBAAoB;QAC7BU,GAAG,EAAC,sBAAsB;QAC1BC,GAAG,EAAC;MAAiB;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACtB,CAAC,eACFnJ,OAAA,CAACP,mBAAmB;QAClBoJ,OAAO,EAAET,mBAAoB;QAC7BU,GAAG,EAAC,0BAA0B;QAC9BC,GAAG,EAAC;MAAa;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAClB,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACe,CAAC;EAExB;AACF,CAAC;AAAC1F,EAAA,CAlTIJ,SAAmC;AAAAgG,EAAA,GAAnChG,SAAmC;AAoTzC,eAAeA,SAAS;AAAC,IAAAgG,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}